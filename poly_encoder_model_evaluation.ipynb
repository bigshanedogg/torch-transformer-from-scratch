{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T16:20:51.097290Z",
     "start_time": "2021-05-25T16:20:49.794812Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "\n",
    "from transformer.assertions.object_assertion import DataAssertion\n",
    "from transformer.utils.tokenizer import MecabTokenizer, SpmTokenizer\n",
    "from transformer.preprocessor.bert_preprocessor import DialogPretrainPreprocessor\n",
    "from transformer.preprocessor.sentence_bert_preprocessor import SentenceBertPreprocessor\n",
    "from transformer.data.dataset import DatasetInterface, DatasetFromDir\n",
    "from transformer.data.bert_data_loader import DialogRetrieverDataLoader\n",
    "from transformer.layers.attention import MultiheadAttention, PositionwiseFeedForward, CodeAttention\n",
    "from transformer.layers.embedding import EmbeddingAggregation\n",
    "from transformer.layers.transformer import EncoderLayer, DecoderLayer\n",
    "from transformer.layers.head import LanguageModelingHead, PolyEncoderHead, NextSentencePredictionHead\n",
    "from transformer.layers.utils import get_pad_mask, get_sub_mask, dot_attention\n",
    "from transformer.models.transformer import Encoder, Decoder, Transformer\n",
    "from transformer.models.bert import Bert\n",
    "from transformer.models.poly_encoder import PolyEncoder\n",
    "from transformer.trainer.bert_trainer import BlenderBotDialogEncoderTrainer\n",
    "from transformer.trainer.poly_encoder_trainer import BlenderBotDialogRetrieverTrainer\n",
    "from transformer.trainer.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AIBUD_DEV\n",
    "# dataset_dir = \"/Users/aibud_dev/_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# # Picas_Server\n",
    "# dataset_dir = \"/home/picas/_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# Korea_Server\n",
    "dataset_dir = \"/home/mnt/guest1\"\n",
    "path = \"./config/file_path.json\"\n",
    "file_path = None\n",
    "with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "    file_path = json.load(fp)\n",
    "\n",
    "# # bigshane_local\n",
    "# dataset_dir = \"D:\\_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_model_dir = dataset_dir + \"/model/bert_dialog_pretrain/20210722/\"\n",
    "# bert_train_config_path = bert_model_dir + ModelFilenameConstants.TRAIN_CONFIG_FILENAME\n",
    "# bert_model_state_dict_path = bert_model_dir + ModelFilenameConstants.MODEL_STATE_DICT_FILENAME\n",
    "# bert_optimizer_state_dict_path = bert_model_dir + ModelFilenameConstants.OPTIMIZER_STATE_DICT_FILENAME\n",
    "# bert_spm_model_path = bert_model_dir + ModelFilenameConstants.SPM_MODEL_DIR\n",
    "# bert_history_path = bert_model_dir + ModelFilenameConstants.HISTORY_FILENAME\n",
    "\n",
    "# # Load config\n",
    "# bert_config = None\n",
    "# with open(bert_train_config_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     bert_config = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = dataset_dir + \"/model/poly_encoder/dialog_retriever/20210803/\"\n",
    "train_config_path = model_dir + ModelFilenameConstants.TRAIN_CONFIG_FILENAME\n",
    "model_hyperparams_path = model_dir + ModelFilenameConstants.MODEL_HYPERPARAMS_FILENAME\n",
    "model_state_dict_path = model_dir + ModelFilenameConstants.MODEL_STATE_DICT_FILENAME\n",
    "optimizer_state_dict_path = model_dir + ModelFilenameConstants.OPTIMIZER_STATE_DICT_FILENAME\n",
    "spm_model_path = model_dir + ModelFilenameConstants.SPM_MODEL_DIR\n",
    "history_path = model_dir + ModelFilenameConstants.HISTORY_FILENAME\n",
    "\n",
    "model_hyperparams = load_hyperparams(path=model_hyperparams_path)\n",
    "# # Load config\n",
    "# config = None\n",
    "# with open(train_config_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     config = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "nprocs = 1\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trainer & Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BlenderBotDialogRetrieverTrainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dfe9defe885b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdialog_retriever_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlenderBotDialogRetrieverTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load prep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msentence_bert_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceBertPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspm_model_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspm_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_hyperparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context_encoder_hyperparams\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timesteps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BlenderBotDialogRetrieverTrainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load trainer\n",
    "dialog_retriever_trainer = BlenderBotDialogRetrieverTrainer()\n",
    "\n",
    "# Load prep\n",
    "sentence_bert_prep = SentenceBertPreprocessor(language=\"kor\", spm_model_path=spm_model_path, embedding_dict=model_hyperparams[\"context_encoder_hyperparams\"][\"embedding_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader_params\n",
    "encoding = \"utf-8\"\n",
    "left_sep_tokens = [[\"cls\", \"sep\"], [None, None]]\n",
    "right_sep_tokens = [[\"cls\", \"sep\"], [None, None]]\n",
    "left_fixed_segment_id = 0 \n",
    "right_fixed_segment_id = 1 # 0\n",
    "approach = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_turn_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_pretrain/kor/multi_turn/\"\n",
    "multi_turn_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_pretrain/kor/single_dataset/KaggleConversation\"\n",
    "# multi_turn_data_dir = dataset_dir + \"/dataset/conversation/SelectStar/kor/multi_turn\"\n",
    "multi_turn_data_extension = \"json\"\n",
    "dialog_dataset = DatasetFromDir(data_dir=multi_turn_data_dir, batch_size=batch_size, encoding=encoding, extension=multi_turn_data_extension, device=device, nprocs=nprocs)\n",
    "dialog_retriever_data_loader_params = BlenderBotDialogRetrieverTrainer.get_data_loader_params(timesteps=model_hyperparams[\"context_encoder_hyperparams\"][\"timesteps\"], left_sep_tokens=left_sep_tokens, right_sep_tokens=right_sep_tokens,\n",
    "                                                                                              left_fixed_segment_id=left_fixed_segment_id, right_fixed_segment_id=right_fixed_segment_id, approach=approach, nprocs=nprocs)\n",
    "dialog_retriever_data_loader = dialog_retriever_trainer.create_data_loader(dataset=dialog_dataset, batch_size=batch_size, preprocessor=sentence_bert_prep, embedding_dict=model_hyperparams[\"context_encoder_hyperparams\"][\"embedding_dict\"],\n",
    "                                                                           num_workers=dialog_retriever_trainer.num_workers, pin_memory=dialog_retriever_trainer.pin_memory, device=device, **dialog_retriever_data_loader_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Poly-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize model & load state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_encoder_model = \"bert\"\n",
    "context_encoder_hyperparams = {\"pad_token_id\":sentence_bert_prep.spm_tokenizer.special_token_dict[\"pad\"][\"id\"], **bert_config[\"model\"]}\n",
    "candidate_encoder_model = \"bert\"\n",
    "candidate_encoder_hyperparams = {\"pad_token_id\":sentence_bert_prep.spm_tokenizer.special_token_dict[\"pad\"][\"id\"], **bert_config[\"model\"]}\n",
    "poly_encoder = PolyEncoder(context_encoder_model=context_encoder_model, context_encoder_hyperparams=context_encoder_hyperparams, candidate_encoder_model=candidate_encoder_model, candidate_encoder_hyperparams=candidate_encoder_hyperparams, m_code=m_code, aggregation_method=aggregation_method)\n",
    "\n",
    "model_dir = \"/home/guest1/torch-transformer/20210806_213831/epoch_9/\"\n",
    "poly_encoder = load_state_dict(object=poly_encoder, path=model_dir, map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load model (with saved hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/home/guest1/torch-transformer/20210806_213831/epoch_9/\"\n",
    "loaded = dialog_retriever_trainer.load(path=model_dir)\n",
    "poly_encoder = loaded[\"model\"]\n",
    "if \"optimizer\" in loaded:\n",
    "    optimizer = loaded[\"optimizer\"]\n",
    "if \"history\" in loaded:\n",
    "    history = loaded[\"history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting model device: cpu\n"
     ]
    }
   ],
   "source": [
    "poly_encoder.eval()\n",
    "poly_encoder = BlenderBotDialogRetrieverTrainer.set_device(obj=poly_encoder, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dialog_response_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = dialog_retriever_trainer.save_dialog_history_set(path=model_dir, model=poly_encoder, data_loader=dialog_retriever_data_loader, device=device)\n",
    "# print(path)\n",
    "# path = dialog_retriever_trainer.save_dialog_response_set(path=model_dir, model=poly_encoder, data_loader=dialog_retriever_data_loader, device=device)\n",
    "# print(path)\n",
    "\n",
    "# dialog_history_set = dialog_retriever_trainer.load_dialog_response_set(path=model_dir)\n",
    "# contexts, encoded_contexts = dialog_history_set\n",
    "dialog_response_set = dialog_retriever_trainer.load_dialog_response_set(path=model_dir)\n",
    "candidates, encoded_candidates = dialog_response_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(dataset, top_n=5, max_retry=5):    \n",
    "    for row in dataset:\n",
    "        candidate_embed = dialog_retriever_trainer.convert_to_tensor(data=encoded_candidates, device=device)\n",
    "        context_input_row, candidate_input_row = dialog_retriever_data_loader.parse_row(row=row)\n",
    "        context_inputs, _, _ = sentence_bert_prep.encode(left_inputs=[context_input_row], right_inputs=[candidate_input_row], timesteps=timesteps,\n",
    "                                                         left_sep_tokens=left_sep_tokens, right_sep_tokens=right_sep_tokens,\n",
    "                                                         left_fixed_segment_id=left_fixed_segment_id, right_fixed_segment_id=right_fixed_segment_id, approach=\"ignore\")\n",
    "        context_inputs = {k:dialog_retriever_trainer.convert_to_tensor(data=v, device=device) for k,v in context_inputs.items()}\n",
    "        if len(context_inputs[\"token\"]) <= 0: continue\n",
    "        context_embed = poly_encoder.encode_context(context_inputs=context_inputs, candidate_embed=candidate_embed)\n",
    "        \n",
    "        context_embed = dialog_retriever_trainer.convert_to_numpy(tensor=context_embed)\n",
    "        candidate_embed = dialog_retriever_trainer.convert_to_numpy(tensor=candidate_embed)\n",
    "        probs = sentence_bert_prep.get_candidate_probs(context_embed=context_embed, candidate_embed=candidate_embed)\n",
    "        scores = sentence_bert_prep.get_top_n_probs(probs=probs[0], top_n=5)\n",
    "        yield context_input_row, candidate_input_row, scores\n",
    "        \n",
    "check_result_iter = check_result(dataset=dialog_dataset, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 여기 있는 사람들이 다 롤러코스터 타려고 기다리는 사람들이야?\n",
      "0: 그런 것 같아요.\n",
      "1: 얼마나 기다려야 할까?\n",
      "0: 최소한 한 시간 반 정도 기다려야 될 것 같아요.\n",
      "1: 한 시간 반? 줄이 너무 기니까 우리 다른 것부터 탈까?\n",
      "\t1) 그게 좋을 것 같아요. (0.8594509232046246)\n",
      "\t2) 성격도 좋고요. (0.12345854404417286)\n",
      "\t3) 쓰레기를 버리는 일이 제일 귀찮아요. (0.007075825937301573)\n",
      "\t4) 고마워요. 편해서 좋아요. (0.0019271001033580588)\n",
      "\t5) 좋아요. 같이 갑시다. (0.0018554869207873684)\n",
      "\tAns) 그게 좋을 것 같아요.\n"
     ]
    }
   ],
   "source": [
    "row, _row, scores = next(check_result_iter)\n",
    "for speaker_id, utterance in zip(row[\"turn\"][0], row[\"token\"][0]):\n",
    "    print(\"{}: {}\".format(speaker_id, utterance))\n",
    "\n",
    "for _idx, (idx, prob) in enumerate(scores):\n",
    "    print(\"\\t{}) {} ({})\".format(_idx+1, candidates[idx], prob))\n",
    "print(\"\\tAns) {}\".format(_row[\"token\"][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    \"여기 있는 사람들이 다 롤러코스터 타려고 기다리는 사람들이야?\", \n",
    "    \"그런 것 같아요.\", \n",
    "    \"얼마나 기다려야 할까?\", \n",
    "    \"최소한 한 시간 반 정도 기다려야 될 것 같아요.\", \n",
    "    \"한 시간 반?\", \n",
    "    \"줄이 너무 기니까 우리 다른 것부터 탈까?\"\n",
    "]\n",
    "[1, 0, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_test(utterances, speaker_ids, top_n=5, max_retry=5):\n",
    "    candidate_embed = dialog_retriever_trainer.convert_to_tensor(data=encoded_candidates, device=device)\n",
    "    context_inputs = sentence_bert_prep.encode_utterances(utterances=utterances, speaker_ids=speaker_ids, timesteps=poly_encoder.context_encoder.timesteps, left_sep_tokens=left_sep_tokens, max_retry=max_retry)\n",
    "    context_inputs = {k:dialog_retriever_trainer.convert_to_tensor(data=v, device=device) for k,v in context_inputs.items()}\n",
    "    context_embed = poly_encoder.encode_context(context_inputs=context_inputs, candidate_embed=candidate_embed)\n",
    "\n",
    "    context_embed = dialog_retriever_trainer.convert_to_numpy(tensor=context_embed)\n",
    "    candidate_embed = dialog_retriever_trainer.convert_to_numpy(tensor=candidate_embed)\n",
    "    probs = sentence_bert_prep.get_candidate_probs(context_embed=context_embed, candidate_embed=candidate_embed)\n",
    "    scores = sentence_bert_prep.get_top_n_probs(probs=probs[0], top_n=5)\n",
    "    \n",
    "    for speaker_id, utterance in zip(speaker_ids, utterances):\n",
    "        print(\"{}: {}\".format(speaker_id, utterance))\n",
    "    \n",
    "    for _idx, (idx, prob) in enumerate(scores):\n",
    "        print(\"\\t{}) {} ({})\".format(_idx, candidates[idx], prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 휴 늦어서 미안해\n",
      "1: 왜 이렇게 늦었어?\n",
      "0: 생각보다 차가 많이 막혔어, 미안\n",
      "1: 저 사람 누군지 알아?\n",
      "\t0) 아니요, 사람이 너무 많아서 못 받았어요. 다음 콘서트에 가면 꼭 사인을 받을 거예요. (0.2763103464327441)\n",
      "\t1) 네, 서울보다 해물이 신선하고 맛있었어요. (0.09542561162156468)\n",
      "\t2) 재미있긴 뭐가 재미있어? 지하철 붐빌 땐 얼마나 불편한데. (0.0833303590960072)\n",
      "\t3) 나는 방학 때 아무 계획도 없는데. 난 뭐 하지? (0.06033457965981522)\n",
      "\t4) 네, 윗집 아주머니가 시험이 끝날 때까지만 양해해 달라고 하셔서 더 불평할 수가 없었어요. (0.06006766015290987)\n"
     ]
    }
   ],
   "source": [
    "utterances = [\n",
    "    \"휴 늦어서 미안해\",\n",
    "    \"왜 이렇게 늦었어?\",\n",
    "    \"생각보다 차가 많이 막혔어, 미안\",\n",
    "    \"저 사람 누군지 알아?\",\n",
    "]\n",
    "speaker_ids = [0, 1, 0, 1]\n",
    "inference_test(utterances=utterances, speaker_ids=speaker_ids, top_n=5, max_retry=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
