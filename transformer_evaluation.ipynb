{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "from bs4 import BeautifulSoup, element\n",
    "import torch\n",
    "\n",
    "from transformer.utils.tokenizer import MecabTokenizer, SpmTokenizer\n",
    "from transformer.trainer.utils import ModelFilenameConstants\n",
    "from transformer.trainer.utils import load_state_dict\n",
    "from transformer.preprocessor.transformer_preprocessor import TransformerPreprocessor, DialogPretrainPreprocessor\n",
    "from transformer.data.dataset import DatasetFromDir\n",
    "from transformer.data.transformer_data_loader import DialogPretrainDataLoader\n",
    "from transformer.models.transformer import Transformer\n",
    "from transformer.trainer.interface import TrainResult, TrainHistory\n",
    "from transformer.trainer.transformer_trainer import TransformerDialogPreTrainer\n",
    "from transformer.preprocessor.utils import split_segment_by_speaker_ids, convert_turn_ids, flatten_sequence\n",
    "from transformer.utils.common import read_all_files_from_dir, set_seed, get_now_str, is_empty_row_in_dict, reset_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AIBUD_DEV\n",
    "# dataset_dir = \"/Users/aibud_dev/_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# # Picas_Server\n",
    "# dataset_dir = \"/home/picas/_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# # Korea_Server\n",
    "# dataset_dir = \"/home/guest1\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# bigshane_local\n",
    "dataset_dir = \"D:\\_jupyter\"\n",
    "path = \"./config/file_path.json\"\n",
    "file_path = None\n",
    "with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "    file_path = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = dataset_dir + \"/model/transformer_dialog_pretrain/20210721/\"\n",
    "train_config_path = model_dir + ModelFilenameConstants.TRAIN_CONFIG_FILENAME\n",
    "model_state_dict_path = model_dir + ModelFilenameConstants.MODEL_STATE_DICT_FILENAME\n",
    "optimizer_state_dict_path = model_dir + ModelFilenameConstants.OPTIMIZER_STATE_DICT_FILENAME\n",
    "src_spm_model_path = model_dir + ModelFilenameConstants.SRC_SPM_MODEL_DIR\n",
    "tgt_spm_model_path = model_dir + ModelFilenameConstants.SRC_SPM_MODEL_DIR\n",
    "history_path = model_dir + ModelFilenameConstants.HISTORY_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config = None\n",
    "with open(train_config_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "    config = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "nprocs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trainer & Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'temp_dir' has been set to './20210728_113127/{mode}_{idx}/' to save model while training\n",
      "Cannot Import konlpy Mecab tagger: <class 'Exception'> - Install MeCab in order to use it: http://konlpy.org/en/latest/install/\n",
      "Importing MeCab for Windows\n",
      "Imported MeCab for Windows successfully\n",
      "loaded spm_model: 'D:\\_jupyter/model/transformer_dialog_pretrain/20210721/src_spm_model/'\n"
     ]
    }
   ],
   "source": [
    "# Load trainer\n",
    "dialog_pretrainer = TransformerDialogPreTrainer()\n",
    "# dialog_pretrainer.set_lr_update(d_model=d_model, num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "# Load prep\n",
    "trfr_prep = DialogPretrainPreprocessor(src_language=config[\"data\"][\"src_language\"], src_spm_model_path=src_spm_model_path, tgt_language=config[\"data\"][\"tgt_language\"], tgt_spm_model_path=tgt_spm_model_path, embedding_dict=config[\"model\"][\"embedding_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### nrpocs:1, device_index:0, num_workers:2, per_proc:849, worker_id:0, iter_start:0, iter_end:424\n",
      "##### nrpocs:1, device_index:0, num_workers:2, per_proc:849, worker_id:1, iter_start:424, iter_end:848\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"KaggleConversation\"\n",
    "data_dir = dataset_dir + \"/dataset/conversation/{dataset_name}/{language}/multi_turn/\".format(dataset_name=dataset_name, language=config[\"data\"][\"src_language\"])\n",
    "dataset = DatasetFromDir(data_dir=data_dir, batch_size=batch_size, encoding=config[\"data\"][\"encoding\"], extension=config[\"data\"][\"extension\"], device=device, nprocs=nprocs)\n",
    "dialog_data_loader_params = TransformerDialogPreTrainer.get_data_loader_params(dataset=dataset, preprocessor=trfr_prep, batch_size=batch_size, \n",
    "                                                                               device=device, nprocs=nprocs, num_workers=dialog_pretrainer.num_workers, pin_memory=dialog_pretrainer.pin_memory,\n",
    "                                                                               **config[\"model\"], **config[\"data_loader\"])\n",
    "kaggle_conversation_data_loader = dialog_pretrainer.create_data_loader(**dialog_data_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"dialog_pretrain\"\n",
    "# # data_dir = dataset_dir + \"/dataset/preprocessed/{dataset_name}/{language}/multi_turn/\".format(dataset_name=dataset_name, language=config[\"data\"][\"src_language\"])\n",
    "# data_dir = dataset_dir + \"/dataset/preprocessed/{dataset_name}/{language}/multi_turn/sample/\".format(dataset_name=dataset_name, language=config[\"data\"][\"src_language\"])\n",
    "# dataset = DatasetFromDir(data_dir=data_dir, batch_size=batch_size, encoding=config[\"data\"][\"encoding\"], extension=config[\"data\"][\"extension\"], device=device, nprocs=nprocs)\n",
    "\n",
    "# dialog_data_loader_params = TransformerDialogPreTrainer.get_data_loader_params(dataset=dataset, preprocessor=trfr_prep, batch_size=batch_size, \n",
    "#                                                                                device=device, nprocs=nprocs, num_workers=dialog_pretrainer.num_workers, pin_memory=dialog_pretrainer.pin_memory,\n",
    "#                                                                                **config[\"model\"], **config[\"data_loader\"])\n",
    "# dialog_pretrain_data_loader = dialog_pretrainer.create_data_loader(**dialog_data_loader_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bert\n",
    "transformer = Transformer(src_timesteps=config[\"model\"][\"src_timesteps\"], tgt_timesteps=config[\"model\"][\"tgt_timesteps\"], src_vocab_size=config[\"model\"][\"src_vocab_size\"], tgt_vocab_size=config[\"model\"][\"tgt_vocab_size\"], \n",
    "                          embedding_dict=config[\"model\"][\"embedding_dict\"], src_pad_token_id=trfr_prep.src_spm_tokenizer.special_token_dict[\"pad\"][\"id\"], tgt_pad_token_id=trfr_prep.tgt_spm_tokenizer.special_token_dict[\"pad\"][\"id\"], \n",
    "                          d_model=config[\"model\"][\"d_model\"], d_ff=config[\"model\"][\"d_ff\"], num_heads=config[\"model\"][\"num_heads\"], \n",
    "                          num_encoder_layers=config[\"model\"][\"num_encoder_layers\"], num_decoder_layers=config[\"model\"][\"num_decoder_layers\"], shared_embedding=config[\"model\"][\"shared_embedding\"], \n",
    "                          dropout=config[\"model\"][\"dropout\"], pwff_activation=config[\"model\"][\"pwff_activation\"], linear_activation=config[\"model\"][\"linear_activation\"], \n",
    "                          bias=config[\"model\"][\"bias\"], layer_norm_epsilon=config[\"model\"][\"layer_norm_epsilon\"], initialization=config[\"model\"][\"initialization\"])\n",
    "transformer = load_state_dict(object=transformer, path=model_state_dict_path, map_location=device)\n",
    "\n",
    "# Load optimizer & criterions\n",
    "optimizer = dialog_pretrainer.get_optimizer(model=transformer, **config[\"train\"][\"optimizer\"])\n",
    "optimizer = load_state_dict(object=optimizer, path=optimizer_state_dict_path, map_location=device)\n",
    "criterions, criterion_weights = dialog_pretrainer.get_criterions(tgt_timesteps=config[\"model\"][\"tgt_timesteps\"], tgt_vocab_size=config[\"model\"][\"tgt_vocab_size\"], tgt_pad_token_id=trfr_prep.tgt_spm_tokenizer.special_token_dict[\"pad\"][\"id\"], **config[\"train\"][\"criterion_weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting model device: cuda:0\n",
      "Setting criterions device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "transformer = TransformerDialogPreTrainer.set_device(obj=transformer, device=device)\n",
    "optimizer = TransformerDialogPreTrainer.set_device(obj=optimizer, device=device)\n",
    "criterions = TransformerDialogPreTrainer.set_device(obj=criterions, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + os.listdir(data_dir)[0], \"r\", encoding=\"utf-8\") as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "verbose_per_batch = 50\n",
    "amp = True\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "# amp = False\n",
    "# scaler = None\n",
    "\n",
    "transformer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_pretrainer.fit(model, train_data_loader: torch.utils.data.DataLoader, val_data_loader: torch.utils.data.DataLoader, criterions, criterion_weights, optimizer, device, epoch: int = 1, amp: bool = False,\n",
    "            save_per_epoch: int = 1, save_per_batch: int = -1, keep_last: bool = True, verbose_per_epoch: int = -1, verbose_per_batch: int = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                 | 1/107 [00:01<02:13,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [ 0 /107]: total_loss: 3.470e-01, lm_loss: 6.935e-01, ul_loss: 3.668e-04,  | total_acc: 8.735e-01, lm_acc: 8.193e-01, ul_acc: 9.277e-01,  | train_time: 1.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▌                                          | 51/107 [00:58<01:04,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [50 /107]: total_loss: 3.531e-01, lm_loss: 7.014e-01, ul_loss: 4.792e-03,  | total_acc: 8.917e-01, lm_acc: 8.406e-01, ul_acc: 9.427e-01,  | train_time: 56.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 101/107 [01:43<00:06,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [100/107]: total_loss: 4.262e-01, lm_loss: 8.044e-01, ul_loss: 4.790e-02,  | total_acc: 8.814e-01, lm_acc: 8.240e-01, ul_acc: 9.388e-01,  | train_time: 45.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 107/107 [01:49<00:00,  1.03s/it]\n",
      "  1%|▊                                                                                 | 1/107 [00:01<02:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [ 0 /107]: total_loss: 3.541e-01, lm_loss: 7.081e-01, ul_loss: 1.028e-05,  | total_acc: 8.735e-01, lm_acc: 8.072e-01, ul_acc: 9.398e-01,  | train_time: 1.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▌                                          | 51/107 [00:58<01:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [50 /107]: total_loss: 3.506e-01, lm_loss: 6.815e-01, ul_loss: 1.976e-02,  | total_acc: 8.938e-01, lm_acc: 8.472e-01, ul_acc: 9.404e-01,  | train_time: 57.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 101/107 [01:43<00:06,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [100/107]: total_loss: 4.103e-01, lm_loss: 7.774e-01, ul_loss: 4.329e-02,  | total_acc: 8.874e-01, lm_acc: 8.369e-01, ul_acc: 9.378e-01,  | train_time: 45.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 107/107 [01:49<00:00,  1.03s/it]\n",
      "  1%|▊                                                                                 | 1/107 [00:01<02:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [ 0 /107]: total_loss: 3.778e-01, lm_loss: 7.531e-01, ul_loss: 2.428e-03,  | total_acc: 8.675e-01, lm_acc: 8.072e-01, ul_acc: 9.277e-01,  | train_time: 1.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▌                                          | 51/107 [00:58<01:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [50 /107]: total_loss: 3.731e-01, lm_loss: 7.268e-01, ul_loss: 1.944e-02,  | total_acc: 8.917e-01, lm_acc: 8.413e-01, ul_acc: 9.420e-01,  | train_time: 57.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 101/107 [01:44<00:06,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [100/107]: total_loss: 4.493e-01, lm_loss: 8.545e-01, ul_loss: 4.417e-02,  | total_acc: 8.768e-01, lm_acc: 8.123e-01, ul_acc: 9.413e-01,  | train_time: 45.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 107/107 [01:50<00:00,  1.03s/it]\n",
      "  1%|▊                                                                                 | 1/107 [00:01<02:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [ 0 /107]: total_loss: 3.386e-01, lm_loss: 6.771e-01, ul_loss: 1.741e-04,  | total_acc: 8.795e-01, lm_acc: 8.313e-01, ul_acc: 9.277e-01,  | train_time: 1.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▌                                          | 51/107 [00:58<01:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [50 /107]: total_loss: 3.491e-01, lm_loss: 6.887e-01, ul_loss: 9.480e-03,  | total_acc: 8.960e-01, lm_acc: 8.497e-01, ul_acc: 9.424e-01,  | train_time: 57.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 101/107 [01:44<00:06,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [100/107]: total_loss: 4.063e-01, lm_loss: 7.520e-01, ul_loss: 6.063e-02,  | total_acc: 8.863e-01, lm_acc: 8.337e-01, ul_acc: 9.390e-01,  | train_time: 45.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 107/107 [01:50<00:00,  1.03s/it]\n",
      "  1%|▊                                                                                 | 1/107 [00:01<02:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [ 0 /107]: total_loss: 3.333e-01, lm_loss: 6.666e-01, ul_loss: 4.893e-05,  | total_acc: 8.795e-01, lm_acc: 8.313e-01, ul_acc: 9.277e-01,  | train_time: 1.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▌                                          | 51/107 [00:59<01:05,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch_train (cuda:0) [50 /107]: total_loss: 3.208e-01, lm_loss: 6.355e-01, ul_loss: 6.175e-03,  | total_acc: 8.995e-01, lm_acc: 8.597e-01, ul_acc: 9.392e-01,  | train_time: 57.0s, lr:  0.0002000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████▋        | 96/107 [01:40<00:12,  1.17s/it]"
     ]
    }
   ],
   "source": [
    "for i in range(0, epoch):\n",
    "    epoch_train_history = None\n",
    "    epoch_result = TrainResult(criterions=criterions)\n",
    "    batch_result = TrainResult(criterions=criterions)\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "        batch_iter_size = len(data)//batch_size + 1\n",
    "        for batch_idx in tqdm(range(0, batch_iter_size)):\n",
    "            batch = data[batch_size*batch_idx:batch_size*(batch_idx+1)]\n",
    "\n",
    "            _src_inputs = []\n",
    "            _tgt_inputs = []\n",
    "            for row in batch:\n",
    "                src_input_row, tgt_input_row = kaggle_conversation_data_loader.parse_json(row)\n",
    "                _src_inputs.append(src_input_row)\n",
    "                _tgt_inputs.append(tgt_input_row)\n",
    "\n",
    "            src_inputs, tgt_inputs, tgt_outputs = kaggle_conversation_data_loader.preprocessor.encode(src_inputs=_src_inputs, tgt_inputs=_tgt_inputs,\n",
    "                                                                                                      src_timesteps=kaggle_conversation_data_loader.src_timesteps, tgt_timesteps=kaggle_conversation_data_loader.tgt_timesteps,\n",
    "                                                                                                      src_sep_tokens=kaggle_conversation_data_loader.src_sep_tokens, approach=kaggle_conversation_data_loader.approach)\n",
    "            batch = src_inputs, tgt_inputs, tgt_outputs\n",
    "            batch = [{k: dialog_pretrainer.convert_to_tensor(data=v, device=device) for k, v in _batch.items()} for _batch in batch]\n",
    "\n",
    "            is_empty_flag = [is_empty_row_in_dict(data=_batch) for _batch in batch]\n",
    "            if any(is_empty_flag): continue\n",
    "            # iteration\n",
    "            loss_dict, acc_dict = dialog_pretrainer.iteration(model=transformer, batch=batch,\n",
    "                                                              criterions=criterions, criterion_weights=criterion_weights,\n",
    "                                                              optimizer=optimizer, train=True, amp=amp, scaler=scaler)\n",
    "            # update train_result instance\n",
    "            batch_result.update(loss_dict=loss_dict, acc_dict=acc_dict, iteration=1, lr=optimizer.param_groups[0][\"lr\"])\n",
    "            # verbose\n",
    "            if verbose_per_batch > 0 and batch_idx % verbose_per_batch == 0:\n",
    "                batch_result.freeze()\n",
    "                print(dialog_pretrainer.verbose_template.format(mode=\"\\nBatch_train\", device=device, idx=batch_idx, num_iters=batch_iter_size), batch_result)\n",
    "                if epoch_train_history is None: epoch_train_history = batch_result.to_train_history()\n",
    "                else: epoch_train_history = epoch_train_history + batch_result.to_train_history()\n",
    "                epoch_result.merge_with(train_result=batch_result)\n",
    "                batch_result = TrainResult(criterions=criterions)\n",
    "\n",
    "        if batch_result.iteration > 0:\n",
    "            epoch_result.merge_with(train_result=batch_result)\n",
    "\n",
    "    dialog_pretrainer.epoch += 1\n",
    "    epoch_result.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_and_targets(data_loader):\n",
    "    for batch_idx in range(0, len(data)//batch_size + 1):\n",
    "        batch = data[batch_size*batch_idx:batch_size*(batch_idx+1)]\n",
    "\n",
    "        _src_inputs = []\n",
    "        _tgt_inputs = []\n",
    "        for row in batch:\n",
    "            src_input_row, tgt_input_row = data_loader.parse_json(row)\n",
    "            _src_inputs.append(src_input_row)\n",
    "            _tgt_inputs.append(tgt_input_row)\n",
    "\n",
    "        src_inputs, tgt_inputs, tgt_outputs = data_loader.preprocessor.encode(src_inputs=_src_inputs, tgt_inputs=_tgt_inputs,\n",
    "                                                                                                  src_timesteps=data_loader.src_timesteps, tgt_timesteps=data_loader.tgt_timesteps,\n",
    "                                                                                                  src_sep_tokens=data_loader.src_sep_tokens, approach=data_loader.approach)\n",
    "        batch = src_inputs, tgt_inputs, tgt_outputs\n",
    "\n",
    "        batch = [{k: dialog_pretrainer.convert_to_tensor(data=v, device=device) for k, v in _batch.items()} for _batch in batch]\n",
    "        src_inputs, tgt_inputs, tgt_outputs = batch\n",
    "\n",
    "        # inference\n",
    "        _predictions = transformer(src_inputs=src_inputs, tgt_inputs=tgt_inputs)\n",
    "        lm_predictions = dialog_pretrainer.convert_to_numpy(tensor=_predictions[\"lm\"])\n",
    "        lm_predictions = np.argmax(lm_predictions, axis=-1)\n",
    "        lm_targets = dialog_pretrainer.convert_to_numpy(tensor=tgt_outputs[\"lm\"])\n",
    "        yield lm_predictions, lm_targets\n",
    "        \n",
    "eos_token_id = trfr_prep.tgt_spm_tokenizer.special_token_dict[\"eos\"][\"id\"]\n",
    "pad_token_id = trfr_prep.tgt_spm_tokenizer.special_token_dict[\"pad\"][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + os.listdir(data_dir)[0], \"r\", encoding=\"utf-8\") as fp:\n",
    "    data = json.load(fp)\n",
    "gen = get_predictions_and_targets(data_loader=kaggle_conversation_data_loader)\n",
    "# gen = get_predictions_and_targets(data_loader=dialog_pretrain_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_predictions, lm_targets = next(gen)\n",
    "label_weights = (lm_targets != pad_token_id).astype(float)\n",
    "correct = (lm_predictions == lm_targets).astype(float)\n",
    "label_correct = correct * label_weights\n",
    "\n",
    "batch_accuracy = np.mean(np.sum(label_correct, axis=-1) / np.sum(label_weights, axis=-1))\n",
    "print(\"batch_accuracy:\", np.round(batch_accuracy, 5), \"\\n\")\n",
    "\n",
    "p = trfr_prep.tgt_decode(lm_predictions.tolist(), eos_token_id=eos_token_id)\n",
    "t = trfr_prep.tgt_decode(lm_targets.tolist(), eos_token_id=eos_token_id)\n",
    "for _p, _t in zip(p, t):\n",
    "    print(\"pred:\", _p)\n",
    "    print(\"targ:\", _t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"KaggleConversation\"\n",
    "language = \"kor\"\n",
    "encoding = \"utf-8\"\n",
    "\n",
    "vocab_size = 15000\n",
    "timesteps = 192\n",
    "embedding_dict = {\"segment\":2, \"turn\":2}\n",
    "sep_tokens = [[\"cls\", \"sep\"], [None, \"sep\"]] # [[\"context\", \"sep\"], [\"candidate\", \"sep\"]]\n",
    "approach = \"ignore\"\n",
    "nprocs = 1\n",
    "\n",
    "# training_params\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialog_pretrainer.num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported konlpy.tag.Mecab successfully\n",
      "loaded spm_model: './data/kor/spoken_pretrain_spm_v15000/'\n"
     ]
    }
   ],
   "source": [
    "spm_model_path = \"./data/{language}/spoken_pretrain_spm_v{vocab_size}\".format(language=language, vocab_size=vocab_size)\n",
    "bert_dialog_prep = DialogPretrainPreprocessor(language=language, spm_model_path=spm_model_path, embedding_dict=embedding_dict)\n",
    "pad_token_id = bert_dialog_prep.spm_tokenizer.special_token_dict[\"pad\"][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'temp_dir' has been set to ./20210710_130826/{mode}_{idx}/ to save model while training\n",
      "worker_info: None\n"
     ]
    }
   ],
   "source": [
    "root_dir = file_path[dataset_name][\"root_dir\"].format(dataset_dir=dataset_dir)\n",
    "raw_dir = file_path[dataset_name][\"raw_dir\"].format(root_dir=root_dir, language=language)\n",
    "multi_turn_data_dir = file_path[dataset_name][\"feed_data\"][\"multi_turn\"].format(root_dir=root_dir, language=language)\n",
    "multi_turn_data_extension = \"json\"\n",
    "\n",
    "dialog_pretrainer = BertDialogPreTrainer()\n",
    "dialog_data_loader_params = BertDialogPreTrainer.get_data_loader_params(timesteps=timesteps, embedding_dict=embedding_dict, nprocs=nprocs, sep_tokens=sep_tokens, approach=approach)\n",
    "dialog_pretrain_dataset = DatasetFromDir(data_dir=multi_turn_data_dir, batch_size=batch_size, encoding=encoding, extension=multi_turn_data_extension, device=device, nprocs=nprocs)\n",
    "dialog_pretrain_data_loader = dialog_pretrainer.create_data_loader(dataset=dialog_pretrain_dataset, batch_size=batch_size, \n",
    "                                                                   num_workers=dialog_pretrainer.num_workers, pin_memory=dialog_pretrainer.pin_memory, preprocessor=bert_dialog_prep, device=device, **dialog_data_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check History files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': OrderedDict([('iteration', [44089]),\n",
       "              ('lr', [0.0001]),\n",
       "              ('train_time', [27746]),\n",
       "              ('loss',\n",
       "               {'mlm': [0.39459580843510916],\n",
       "                'nsp': [0.2841686550899227],\n",
       "                'total_loss': [0.3393822317625159]}),\n",
       "              ('acc',\n",
       "               {'mlm': [0.8877814241079436],\n",
       "                'nsp': [0.6865681933667592],\n",
       "                'total_acc': [0.7871748087373515]})]),\n",
       " 'val': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "history_path = model_dir + ModelFilenameConstants.HISTORY_FILENAME\n",
    "with open(history_path, \"rb\") as fp:\n",
    "    history = pickle.load(fp)\n",
    "dict(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(self, sequences: List[List[str]], preprocessor: Preprocessor, device:str, method: str = \"greedy\") -> str:\n",
    "    self.to(device, non_blocking=True)\n",
    "    self.assert_isin_methods(method=method)\n",
    "\n",
    "    src_input_row = preprocessor.src_encode(sentence=src_sentence, mask=False)\n",
    "    if not preprocessor.is_proper_length(ids=src_input_row, upper_bound=self.src_timesteps): preprocessor._raise_approach_error(approach=\"stop\")\n",
    "    src_input_row = preprocessor.pad_row(ids=src_input_row, timesteps=self.src_timesteps, padding_value=self.src_pad_token_id)\n",
    "    tgt_input_row = [self.tgt_pad_token_id] * self.tgt_timesteps\n",
    "    src_inputs = np.expand_dims(np.array(src_input_row), axis=0)\n",
    "    tgt_inputs = np.expand_dims(np.array(tgt_input_row), axis=0)\n",
    "\n",
    "    if device is None:\n",
    "        src_inputs = torch.from_numpy(src_inputs)\n",
    "        tgt_inputs = torch.from_numpy(tgt_inputs)\n",
    "    else:\n",
    "        src_inputs = torch.from_numpy(src_inputs).to(device)\n",
    "        tgt_inputs = torch.from_numpy(tgt_inputs).to(device)\n",
    "\n",
    "    tgt_bos_token_id = preprocessor.tgt_spm_tokenizer.special_token_dict[\"bos\"][\"id\"]\n",
    "    tgt_eos_token_id = preprocessor.tgt_spm_tokenizer.special_token_dict[\"eos\"][\"id\"]\n",
    "    if method == \"greedy\":\n",
    "        return self._inference_greedy(src_inputs=src_inputs, tgt_inputs=tgt_inputs, tgt_bos_token_id=tgt_bos_token_id, tgt_eos_token_id=tgt_eos_token_id)\n",
    "    elif method == \"beam_search\":\n",
    "        return self._inference_beam_search(src_inputs=src_inputs, tgt_inputs=tgt_inputs, tgt_bos_token_id=tgt_bos_token_id, tgt_eos_token_id=tgt_eos_token_id)\n",
    "\n",
    "def _inference_greedy(self, src_inputs, tgt_inputs, tgt_bos_token_id, tgt_eos_token_id):\n",
    "    output = []\n",
    "    next_token_id = tgt_bos_token_id\n",
    "    for timestep in range(0, self.tgt_timesteps):\n",
    "        tgt_inputs[0][timestep] = next_token_id\n",
    "        prediction_rows = self.forward(src_inputs=src_inputs, tgt_inputs=tgt_inputs)\n",
    "        prediction_row = torch.argmax(prediction_rows, dim=-1)[0]\n",
    "        next_token_id = prediction_row[timestep].tolist()\n",
    "        output.append(next_token_id)\n",
    "        if next_token_id == tgt_eos_token_id: break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
