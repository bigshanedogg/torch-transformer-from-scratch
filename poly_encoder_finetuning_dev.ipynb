{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setproctitle import setproctitle\n",
    "setproctitle(\"Hodong_PolyEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T16:20:51.097290Z",
     "start_time": "2021-05-25T16:20:49.794812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aibud_dev/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py:118: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
      "/Users/aibud_dev/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py:118: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "\n",
    "from transformer.assertions.object_assertion import DataAssertion\n",
    "from transformer.utils.tokenizer import MecabTokenizer, SpmTokenizer\n",
    "from transformer.data.dataset import DatasetInterface, DatasetFromDir\n",
    "from transformer.models.bert import Bert\n",
    "from transformer.models.poly_encoder import PolyEncoder\n",
    "\n",
    "from transformer.preprocessors.blender_bot_preprocessor import RetrieverFinetuningPreprocessor\n",
    "from transformer.data.blender_bot_data_loader import RetrieverFinetuningDataLoader\n",
    "from transformer.trainers.bert_trainer import BertTrainer\n",
    "from transformer.trainers.blender_bot_trainer import RetrieverEncoderBertTrainer, RetrieverFinetuningPolyEncoderTrainer\n",
    "from transformer.trainers.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIBUD_DEV\n",
    "dataset_dir = \"/Users/aibud_dev/_jupyter\"\n",
    "path = \"./config/file_path.json\"\n",
    "file_path = None\n",
    "with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "    file_path = json.load(fp)\n",
    "\n",
    "# # Picas_Server\n",
    "# dataset_dir = \"/home/picas/_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# # Korea_Server\n",
    "# dataset_dir = \"/home/mnt/guest1\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# # bigshane_local\n",
    "# dataset_dir = \"D:\\_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly_encoder config\n",
    "with open(\"./scripts/poly_encoder/config/retriever_finetuning_korea.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "# encoder config\n",
    "encoder_model_dir = dataset_dir + \"/model/bert/dialog_pretrain/20210722/\"\n",
    "encoder_config_path = encoder_model_dir + ModelFilenameConstants.TRAIN_CONFIG_FILENAME\n",
    "encoder_model_state_dict_path = encoder_model_dir + ModelFilenameConstants.MODEL_STATE_DICT_FILENAME\n",
    "encoder_optimizer_state_dict_path = encoder_model_dir + ModelFilenameConstants.OPTIMIZER_STATE_DICT_FILENAME\n",
    "encoder_spm_model_path = encoder_model_dir + ModelFilenameConstants.SPM_MODEL_DIR\n",
    "encoder_config = None\n",
    "with open(encoder_config_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "    encoder_config = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported konlpy.tag.Mecab successfully\n",
      "loaded spm_model: '/Users/aibud_dev/_jupyter/spm_model/kor/spoken_pretrain_spm_v15000/'\n"
     ]
    }
   ],
   "source": [
    "spm_model_path = dataset_dir + \"/spm_model/{language}/spoken_pretrain_spm_v{vocab_size}\".format(language=config[\"data\"][\"language\"], vocab_size=encoder_config[\"model\"][\"vocab_size\"])\n",
    "# spm_model_path = config[\"data\"][\"spm_model_path\"].format(root_dir=config[\"data\"][\"root_dir\"], language=config[\"data\"][\"language\"], vocab_size=encoder_config[\"model\"][\"vocab_size\"])\n",
    "preprocessor = RetrieverFinetuningPreprocessor(language=config[\"data\"][\"language\"], spm_model_path=spm_model_path, embedding_dict=encoder_config[\"model\"][\"embedding_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'temp_dir' has been set to '/Users/aibud_dev/_jupyter/model/temp/20210826_193041/' to save model while training\n",
      "LearningRate schedule has been set to 'transformer_lambda'\n"
     ]
    }
   ],
   "source": [
    "trainer = RetrieverFinetuningPolyEncoderTrainer(temp_dir=dataset_dir+\"/model/temp/\")\n",
    "# trainer = RetrieverFinetuningPolyEncoderTrainer(temp_dir=config[\"train\"][\"temp_save_path\"])\n",
    "trainer.set_lr_update(initial_learning_rate=config[\"optimizer\"][\"initial_learning_rate\"], num_warmup_steps=config[\"train\"][\"num_warmup_steps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-GPU Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build PolyEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initial Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # context_encoder\n",
    "# context_encoder = Bert(pad_token_id=preprocessor.spm_tokenizer.special_token_dict[\"pad\"][\"id\"], **encoder_config[\"model\"])\n",
    "# context_encoder = load_state_dict(object=context_encoder, path=encoder_model_state_dict_path)\n",
    "# # candidate_encoder\n",
    "# candidate_encoder = Bert(pad_token_id=preprocessor.spm_tokenizer.special_token_dict[\"pad\"][\"id\"], **encoder_config[\"model\"])\n",
    "# candidate_encoder = load_state_dict(object=candidate_encoder, path=encoder_model_state_dict_path)\n",
    "# # poly_encoder\n",
    "# poly_encoder = PolyEncoder(context_encoder=context_encoder, candidate_encoder=candidate_encoder, **config[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = dataset_dir + \"/model/poly_encoder/dialog_retriever/20210803/\"\n",
    "# context_encoder\n",
    "context_encoder_model_path = dataset_dir + \"/model/bert/dialog_pretrain/20210722/\"\n",
    "# context_encoder_model_path = model_dir + \"context_encoder/\"\n",
    "# context_encoder_model_path = config[\"model\"][\"context_encoder\"][\"model_path\"]\n",
    "context_encoder = trainer.create_encoder(model_type=config[\"model\"][\"context_encoder\"][\"model_type\"], encoder_model_path=context_encoder_model_path)\n",
    "# candidate_encoder\n",
    "candidate_encoder_model_path = dataset_dir + \"/model/bert/dialog_pretrain/20210722/\"\n",
    "# candidate_encoder_model_path = model_dir + \"candidate_encoder/\"\n",
    "# candidate_encoder_model_path = config[\"model\"][\"candidate_encoder\"][\"model_path\"]\n",
    "candidate_encoder = trainer.create_encoder(model_type=config[\"model\"][\"candidate_encoder\"][\"model_type\"], encoder_model_path=candidate_encoder_model_path)\n",
    "# poly_encoder\n",
    "poly_encoder = trainer.create_model(context_encoder=context_encoder, candidate_encoder=candidate_encoder, m_code=config[\"model\"][\"m_code\"], aggregation_method=config[\"model\"][\"aggregation_method\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_encoder = load_state_dict(object=poly_encoder, path=model_dir + ModelFilenameConstants.MODEL_STATE_DICT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set criterions & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterions, criterion_weights = trainer.get_criterions(**config[\"criterion\"])\n",
    "optimizer = trainer.get_optimizer(model=poly_encoder, **config[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting model device: cpu\n",
      "Setting criterions device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "poly_encoder = BertTrainer.set_device(obj=poly_encoder, device=device)\n",
    "optimizer = BertTrainer.set_device(obj=optimizer, device=device)\n",
    "criterions = BertTrainer.set_device(obj=criterions, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader_params\n",
    "batch_size = 4\n",
    "nprocs = 1\n",
    "\n",
    "total_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_retriever/kor/multi_turn/\"\n",
    "sample_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_retriever/kor/multi_turn/sample/\"\n",
    "train_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_retriever/kor/multi_turn/train/\"\n",
    "val_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_retriever/kor/multi_turn/val/\"\n",
    "\n",
    "train_dataset = DatasetFromDir(data_dir=sample_data_dir, batch_size=batch_size, device=device, nprocs=nprocs, encoding=config[\"data\"][\"encoding\"], extension=config[\"data\"][\"extension\"])\n",
    "train_data_loader_params = trainer.get_data_loader_params(dataset=train_dataset, preprocessor=preprocessor, batch_size=batch_size, device=device, nprocs=nprocs, **config[\"data_loader\"], **encoder_config[\"model\"])\n",
    "train_data_loader = trainer.create_data_loader(**train_data_loader_params)\n",
    "\n",
    "val_dataset = DatasetFromDir(data_dir=val_data_dir, batch_size=batch_size, device=device, nprocs=nprocs, encoding=config[\"data\"][\"encoding\"], extension=config[\"data\"][\"extension\"])\n",
    "val_data_loader_params = trainer.get_data_loader_params(dataset=val_dataset, preprocessor=preprocessor, batch_size=batch_size, device=device, nprocs=nprocs, **config[\"data_loader\"], **encoder_config[\"model\"])\n",
    "val_data_loader = trainer.create_data_loader(**val_data_loader_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_loader.summary(show_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader encode test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_idx = 2\n",
    "# context_inputs, candidate_inputs, outputs = train_data_loader.get_batch()\n",
    "\n",
    "# print(\"ctxt_token:\\t\", [token_idx for token_idx in range(0, len(context_inputs[\"token\"][row_idx])) if token_idx==0 or context_inputs[\"token\"][row_idx][token_idx]==preprocessor.spm_tokenizer.special_token_dict[\"sep\"][\"id\"]])\n",
    "# print(\"ctxt_segment:\\t\", [token_idx for token_idx in range(0, len(context_inputs[\"segment\"][row_idx])-1) if token_idx==0 or context_inputs[\"segment\"][row_idx][token_idx]!=context_inputs[\"segment\"][row_idx][token_idx+1]])\n",
    "# print(\"ctxt_turn:\\t\", [token_idx for token_idx in range(0, len(context_inputs[\"turn\"][row_idx])-1) if token_idx==0 or context_inputs[\"turn\"][row_idx][token_idx]!=context_inputs[\"turn\"][row_idx][token_idx+1]])\n",
    "# print()\n",
    "# print(\"cdnd_token:\\t\", [token_idx for token_idx in range(0, len(candidate_inputs[\"token\"][row_idx])) if token_idx==0 or candidate_inputs[\"token\"][row_idx][token_idx]==preprocessor.spm_tokenizer.special_token_dict[\"sep\"][\"id\"]])\n",
    "# print(\"cdnd_segment:\\t\", [token_idx for token_idx in range(0, len(candidate_inputs[\"segment\"][row_idx])-1) if token_idx==0 or candidate_inputs[\"segment\"][row_idx][token_idx]!=candidate_inputs[\"segment\"][row_idx][token_idx+1]])\n",
    "# print(\"cdnd_turn:\\t\", [token_idx for token_idx in range(0, len(candidate_inputs[\"turn\"][row_idx])-1) if token_idx==0 or candidate_inputs[\"turn\"][row_idx][token_idx]!=candidate_inputs[\"turn\"][row_idx][token_idx+1]])\n",
    "\n",
    "# for ctxt_token, cdnd_token, ce_label in zip(preprocessor.decode(context_inputs[\"token\"]), preprocessor.decode(candidate_inputs[\"token\"]), outputs[\"ce\"]):\n",
    "#     print(\"ce_label:\\t\", ce_label)\n",
    "#     print(\"ctxt_token:\\t\", ctxt_token)\n",
    "#     print(\"cdnd_token:\\t\", cdnd_token)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aibud_dev/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:116: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "epoch = 200\n",
    "amp = True\n",
    "scaler = None\n",
    "if amp: scaler = torch.cuda.amp.GradScaler()\n",
    "save_per_epoch = 1\n",
    "save_per_batch = -1\n",
    "keep_last = False\n",
    "verbose_per_epoch = 1\n",
    "verbose_per_batch = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainer.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.fit(model=poly_encoder, train_data_loader=train_data_loader, val_data_loader=val_data_loader, \n",
    "                      criterions=criterions, criterion_weights=criterion_weights, optimizer=optimizer, device=device, \n",
    "                      epoch=epoch, amp=amp, save_per_epoch=save_per_epoch, save_per_batch=save_per_batch, keep_last=keep_last, verbose_per_epoch=verbose_per_epoch, verbose_per_batch=verbose_per_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainer.train_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = tqdm(train_data_loader, initial=train_data_loader.iter_start, total=len(train_data_loader))\n",
    "data_iter.iter_size = train_data_loader.iter_end - train_data_loader.iter_start\n",
    "epoch_train_history = trainer.train_epoch(model=poly_encoder, data_loader=data_iter, \n",
    "                                          criterions=criterions, criterion_weights=criterion_weights, optimizer=optimizer, device=device, \n",
    "                                          amp=amp, scaler=scaler, save_per_batch=save_per_batch, verbose_per_batch=verbose_per_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainer.iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aibud_dev/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py:118: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in enumerate(train_data_loader):\n",
    "    batch_idx += 1\n",
    "    batch = [{k: trainer.convert_to_tensor(data=v, device=device) for k, v in _batch.items()} for _batch in batch]\n",
    "\n",
    "    loss_dict, acc_dict = trainer.iteration(model=poly_encoder, batch=batch,\n",
    "                                            criterions=criterions, criterion_weights=criterion_weights, optimizer=optimizer, \n",
    "                                            train=True, amp=amp, scaler=scaler)\n",
    "    \n",
    "    print(loss_dict)\n",
    "    print(acc_dict)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_dir = \"/home/mnt/guest1/model/poly_encoder/dialog_retriever/20210813/\"\n",
    "# trainer.save(path=_model_dir, model=transformer, optimizer=optimizer, history=None, config=config, preprocessor=preprocessor, save_model_hyperparams=True, save_optimizer_hyperparams=False, ddp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.services.dialog_retriever.poly_encoder import DialogRetriever\n",
    "dr = DialogRetriever(temp_dir=\"./\")\n",
    "dr.load_model(model_dir=_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = [\n",
    "    \"여기 있는 사람들이 다 롤러코스터 타려고 기다리는 사람들이야?\",\n",
    "    \"그런 것 같아요.\",\n",
    "    \"얼마나 기다려야 할까?\",\n",
    "    \"최소한 한 시간 반 정도 기다려야 될 것 같아요.\",\n",
    "    \"한 시간 반?\",\n",
    "    \"줄이 너무 기니까 우리 다른 것부터 탈까?\"\n",
    "]\n",
    "speaker_ids = [1, 0, 1, 0, 1, 1]\n",
    "top_n = 5\n",
    "max_retry = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy\n",
    "output = dr.infer_next_utterance(utterances=utterances, speaker_ids=speaker_ids, top_n=top_n, max_retry=max_retry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
